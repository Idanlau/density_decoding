{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166e0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from DAPT.tools import runner_finetune, runner_pretrain\n",
    "from DAPT.utils.config import cfg_from_yaml_file, log_args_to_file, log_config_to_file\n",
    "from DAPT.utils.logger import get_root_logger\n",
    "from DAPT.utils.parser import get_args\n",
    "from density_decoding.utils.data_utils import IBLDataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb88fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dapt_args = get_args(\"--exp_name debug --config DAPT/cfgs/finetune_modelnet_dapt.yaml --num_workers 0\")\n",
    "gmm_args = Namespace(pid=\"5246af08-0730-40f7-83de-29b5d62b9b6d\", n_t_bins=30, prior_path=None, ephys_path=\"ephys_data/c51f34d8-42f6-4c9c-bb5b-669fd9c42cd9_angelakilab_NYU_48\", behavior=\"choice\", brain_region=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbd2c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling data from ibl database ..\n",
      "eid: c51f34d8-42f6-4c9c-bb5b-669fd9c42cd9\n",
      "pid: 5246af08-0730-40f7-83de-29b5d62b9b6d\n",
      "number of trials found: 415 (active: 415)\n",
      "prior for this session is not found.\n",
      "found 415 trials from 65.80 to 2646.26 sec.\n",
      "available brain regions to decode:\n",
      "['CA1' 'CA3' 'DG-mo' 'DG-po' 'DG-sg' 'LP' 'TH' 'VISa6a' 'VISa6b' 'VISam6a'\n",
      " 'VISpm2/3' 'VISpm4' 'VISpm5' 'VPL' 'VPM' 'ZI' 'bsc' 'fp' 'ml' 'or' 'root']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process spike features (whole trial): 100%|██████████| 415/415 [00:20<00:00, 20.46it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ibl_data_loader = IBLDataLoader(\n",
    "        gmm_args.pid,\n",
    "        n_t_bins = gmm_args.n_t_bins,\n",
    "        prior_path = gmm_args.prior_path\n",
    "    )\n",
    "\n",
    "    print(\"available brain regions to decode:\")\n",
    "    ibl_data_loader.check_available_brain_regions()\n",
    "    \n",
    "    behavior = ibl_data_loader.process_behaviors(gmm_args.behavior)\n",
    "\n",
    "    spike_index = np.load(os.path.join(gmm_args.ephys_path, \"spike_index.npy\"))\n",
    "    spike_features_exp = np.load(os.path.join(gmm_args.ephys_path, \"localization_results.npy\"))\n",
    "    spike_times, spike_channels = spike_index.T\n",
    "    \n",
    "    spike_features, trial_idxs = \\\n",
    "        ibl_data_loader.load_spike_feats_trial(\n",
    "            spike_times, spike_channels, spike_features_exp, gmm_args.brain_region\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9a6ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(spikes.shape[0] for spikes in spike_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f14cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeEvents(Dataset):\n",
    "    \n",
    "    def __init__(self, spike_features, labels):\n",
    "        self.spike_features = spike_features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.spike_features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        spikes = torch.from_numpy(self.spike_features[index]).float()[:1024]\n",
    "        # indices = torch.randperm(len(spikes))\n",
    "        return \"Ephys\", \"Spikes\", (spikes, self.labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad200009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "runner_finetune.train_transforms = transforms.Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "058e0dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 22:31:25,555 - finetune_modelnet_dapt - INFO - args.config : DAPT/cfgs/finetune_modelnet_dapt.yaml\n",
      "2025-04-24 22:31:25,556 - finetune_modelnet_dapt - INFO - args.launcher : none\n",
      "2025-04-24 22:31:25,557 - finetune_modelnet_dapt - INFO - args.local_rank : 0\n",
      "2025-04-24 22:31:25,558 - finetune_modelnet_dapt - INFO - args.num_workers : 0\n",
      "2025-04-24 22:31:25,559 - finetune_modelnet_dapt - INFO - args.seed : 0\n",
      "2025-04-24 22:31:25,560 - finetune_modelnet_dapt - INFO - args.deterministic : False\n",
      "2025-04-24 22:31:25,560 - finetune_modelnet_dapt - INFO - args.sync_bn : False\n",
      "2025-04-24 22:31:25,562 - finetune_modelnet_dapt - INFO - args.exp_name : debug\n",
      "2025-04-24 22:31:25,563 - finetune_modelnet_dapt - INFO - args.loss : cd1\n",
      "2025-04-24 22:31:25,564 - finetune_modelnet_dapt - INFO - args.start_ckpts : None\n",
      "2025-04-24 22:31:25,566 - finetune_modelnet_dapt - INFO - args.ckpts : None\n",
      "2025-04-24 22:31:25,567 - finetune_modelnet_dapt - INFO - args.val_freq : 1\n",
      "2025-04-24 22:31:25,567 - finetune_modelnet_dapt - INFO - args.vote : False\n",
      "2025-04-24 22:31:25,568 - finetune_modelnet_dapt - INFO - args.tsne : False\n",
      "2025-04-24 22:31:25,569 - finetune_modelnet_dapt - INFO - args.resume : False\n",
      "2025-04-24 22:31:25,571 - finetune_modelnet_dapt - INFO - args.test : False\n",
      "2025-04-24 22:31:25,572 - finetune_modelnet_dapt - INFO - args.finetune_model : False\n",
      "2025-04-24 22:31:25,573 - finetune_modelnet_dapt - INFO - args.scratch_model : False\n",
      "2025-04-24 22:31:25,574 - finetune_modelnet_dapt - INFO - args.mode : None\n",
      "2025-04-24 22:31:25,575 - finetune_modelnet_dapt - INFO - args.way : -1\n",
      "2025-04-24 22:31:25,575 - finetune_modelnet_dapt - INFO - args.shot : -1\n",
      "2025-04-24 22:31:25,576 - finetune_modelnet_dapt - INFO - args.fold : -1\n",
      "2025-04-24 22:31:25,577 - finetune_modelnet_dapt - INFO - args.experiment_path : ./experiments/finetune_modelnet_dapt/cfgs/debug\n",
      "2025-04-24 22:31:25,578 - finetune_modelnet_dapt - INFO - args.tfboard_path : ./experiments/finetune_modelnet_dapt/cfgs/TFBoard/debug\n",
      "2025-04-24 22:31:25,578 - finetune_modelnet_dapt - INFO - args.log_name : finetune_modelnet_dapt\n",
      "2025-04-24 22:31:25,579 - finetune_modelnet_dapt - INFO - config.optimizer = edict()\n",
      "2025-04-24 22:31:25,580 - finetune_modelnet_dapt - INFO - config.optimizer.type : AdamW\n",
      "2025-04-24 22:31:25,581 - finetune_modelnet_dapt - INFO - config.optimizer.part : dapt\n",
      "2025-04-24 22:31:25,582 - finetune_modelnet_dapt - INFO - config.optimizer.kwargs = edict()\n",
      "2025-04-24 22:31:25,583 - finetune_modelnet_dapt - INFO - config.optimizer.kwargs.lr : 1e-05\n",
      "2025-04-24 22:31:25,584 - finetune_modelnet_dapt - INFO - config.optimizer.kwargs.weight_decay : 0.05\n",
      "2025-04-24 22:31:25,584 - finetune_modelnet_dapt - INFO - config.scheduler = edict()\n",
      "2025-04-24 22:31:25,585 - finetune_modelnet_dapt - INFO - config.scheduler.type : function\n",
      "2025-04-24 22:31:25,586 - finetune_modelnet_dapt - INFO - config.scheduler.kwargs = edict()\n",
      "2025-04-24 22:31:25,587 - finetune_modelnet_dapt - INFO - config.scheduler.kwargs.epochs : 300\n",
      "2025-04-24 22:31:25,592 - finetune_modelnet_dapt - INFO - config.scheduler.kwargs.initial_epochs : 10\n",
      "2025-04-24 22:31:25,592 - finetune_modelnet_dapt - INFO - config.dataset = edict()\n",
      "2025-04-24 22:31:25,593 - finetune_modelnet_dapt - INFO - config.dataset.train = edict()\n",
      "2025-04-24 22:31:25,594 - finetune_modelnet_dapt - INFO - config.dataset.train._base_ = edict()\n",
      "2025-04-24 22:31:25,594 - finetune_modelnet_dapt - INFO - config.dataset.train._base_.NAME : ModelNet\n",
      "2025-04-24 22:31:25,595 - finetune_modelnet_dapt - INFO - config.dataset.train._base_.DATA_PATH : data/ModelNet/modelnet40_normal_resampled\n",
      "2025-04-24 22:31:25,596 - finetune_modelnet_dapt - INFO - config.dataset.train._base_.N_POINTS : 8192\n",
      "2025-04-24 22:31:25,596 - finetune_modelnet_dapt - INFO - config.dataset.train._base_.NUM_CATEGORY : 40\n",
      "2025-04-24 22:31:25,598 - finetune_modelnet_dapt - INFO - config.dataset.train._base_.USE_NORMALS : False\n",
      "2025-04-24 22:31:25,599 - finetune_modelnet_dapt - INFO - config.dataset.train.others = edict()\n",
      "2025-04-24 22:31:25,600 - finetune_modelnet_dapt - INFO - config.dataset.train.others.subset : train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 22:31:25,600 - finetune_modelnet_dapt - INFO - config.dataset.val = edict()\n",
      "2025-04-24 22:31:25,601 - finetune_modelnet_dapt - INFO - config.dataset.val._base_ = edict()\n",
      "2025-04-24 22:31:25,602 - finetune_modelnet_dapt - INFO - config.dataset.val._base_.NAME : ModelNet\n",
      "2025-04-24 22:31:25,603 - finetune_modelnet_dapt - INFO - config.dataset.val._base_.DATA_PATH : data/ModelNet/modelnet40_normal_resampled\n",
      "2025-04-24 22:31:25,604 - finetune_modelnet_dapt - INFO - config.dataset.val._base_.N_POINTS : 8192\n",
      "2025-04-24 22:31:25,604 - finetune_modelnet_dapt - INFO - config.dataset.val._base_.NUM_CATEGORY : 40\n",
      "2025-04-24 22:31:25,605 - finetune_modelnet_dapt - INFO - config.dataset.val._base_.USE_NORMALS : False\n",
      "2025-04-24 22:31:25,606 - finetune_modelnet_dapt - INFO - config.dataset.val.others = edict()\n",
      "2025-04-24 22:31:25,607 - finetune_modelnet_dapt - INFO - config.dataset.val.others.subset : test\n",
      "2025-04-24 22:31:25,608 - finetune_modelnet_dapt - INFO - config.dataset.test = edict()\n",
      "2025-04-24 22:31:25,608 - finetune_modelnet_dapt - INFO - config.dataset.test._base_ = edict()\n",
      "2025-04-24 22:31:25,609 - finetune_modelnet_dapt - INFO - config.dataset.test._base_.NAME : ModelNet\n",
      "2025-04-24 22:31:25,610 - finetune_modelnet_dapt - INFO - config.dataset.test._base_.DATA_PATH : data/ModelNet/modelnet40_normal_resampled\n",
      "2025-04-24 22:31:25,610 - finetune_modelnet_dapt - INFO - config.dataset.test._base_.N_POINTS : 8192\n",
      "2025-04-24 22:31:25,611 - finetune_modelnet_dapt - INFO - config.dataset.test._base_.NUM_CATEGORY : 40\n",
      "2025-04-24 22:31:25,612 - finetune_modelnet_dapt - INFO - config.dataset.test._base_.USE_NORMALS : False\n",
      "2025-04-24 22:31:25,613 - finetune_modelnet_dapt - INFO - config.dataset.test.others = edict()\n",
      "2025-04-24 22:31:25,613 - finetune_modelnet_dapt - INFO - config.dataset.test.others.subset : test\n",
      "2025-04-24 22:31:25,614 - finetune_modelnet_dapt - INFO - config.model = edict()\n",
      "2025-04-24 22:31:25,615 - finetune_modelnet_dapt - INFO - config.model.NAME : PointTransformer_DAPT\n",
      "2025-04-24 22:31:25,615 - finetune_modelnet_dapt - INFO - config.model.trans_dim : 384\n",
      "2025-04-24 22:31:25,616 - finetune_modelnet_dapt - INFO - config.model.depth : 12\n",
      "2025-04-24 22:31:25,617 - finetune_modelnet_dapt - INFO - config.model.drop_path_rate : 0.1\n",
      "2025-04-24 22:31:25,617 - finetune_modelnet_dapt - INFO - config.model.drop_rate : 0.0\n",
      "2025-04-24 22:31:25,618 - finetune_modelnet_dapt - INFO - config.model.cls_dim : 2\n",
      "2025-04-24 22:31:25,619 - finetune_modelnet_dapt - INFO - config.model.num_heads : 6\n",
      "2025-04-24 22:31:25,620 - finetune_modelnet_dapt - INFO - config.model.group_size : 32\n",
      "2025-04-24 22:31:25,620 - finetune_modelnet_dapt - INFO - config.model.num_group : 64\n",
      "2025-04-24 22:31:25,621 - finetune_modelnet_dapt - INFO - config.model.encoder_dims : 384\n",
      "2025-04-24 22:31:25,622 - finetune_modelnet_dapt - INFO - config.model.rank : 72\n",
      "2025-04-24 22:31:25,622 - finetune_modelnet_dapt - INFO - config.model.drop_adapter_rate : 0\n",
      "2025-04-24 22:31:25,623 - finetune_modelnet_dapt - INFO - config.model.class_token : use\n",
      "2025-04-24 22:31:25,624 - finetune_modelnet_dapt - INFO - config.model.prompt_token : None\n",
      "2025-04-24 22:31:25,624 - finetune_modelnet_dapt - INFO - config.model.patch_token : max\n",
      "2025-04-24 22:31:25,625 - finetune_modelnet_dapt - INFO - config.npoints : 1024\n",
      "2025-04-24 22:31:25,625 - finetune_modelnet_dapt - INFO - config.total_bs : 32\n",
      "2025-04-24 22:31:25,626 - finetune_modelnet_dapt - INFO - config.step_per_update : 1\n",
      "2025-04-24 22:31:25,627 - finetune_modelnet_dapt - INFO - config.max_epoch : 100\n",
      "2025-04-24 22:31:25,628 - finetune_modelnet_dapt - INFO - config.grad_norm_clip : 10\n"
     ]
    }
   ],
   "source": [
    "# logger\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "log_file = os.path.join(dapt_args.experiment_path, f'{timestamp}.log')\n",
    "logger = get_root_logger(log_file=log_file, name=dapt_args.log_name)\n",
    "config = cfg_from_yaml_file(dapt_args.config)\n",
    "config.npoints = 1024\n",
    "config.max_epoch = 100\n",
    "config.model.cls_dim = 2\n",
    "config.optimizer.kwargs.lr = 0.00001\n",
    "config.scheduler.type = \"function\"\n",
    "log_args_to_file(dapt_args, 'args', logger=logger)\n",
    "log_config_to_file(config, 'config', logger=logger)\n",
    "\n",
    "train_writer = SummaryWriter(os.path.join(dapt_args.tfboard_path, 'train'))\n",
    "val_writer = SummaryWriter(os.path.join(dapt_args.tfboard_path, 'test'))\n",
    "spike_feat_train, spike_feat_test, behav_train, behav_test = train_test_split(spike_features, behavior, stratify=behavior)\n",
    "train_data, test_data = SpikeEvents(spike_feat_train, behav_train), SpikeEvents(spike_feat_test, behav_test)\n",
    "train_loader = DataLoader(train_data, batch_size=20, shuffle=True, drop_last=True, num_workers=int(dapt_args.num_workers))\n",
    "test_loader = DataLoader(train_data, batch_size=20, shuffle=False, drop_last=False, num_workers=int(dapt_args.num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba9e5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 22:31:51,576 - Transformer - INFO - Mismatched keys: ['encoder.first_conv.0.weight', 'pos_embed.0.weight', 'cls_head_finetune.8.weight', 'cls_head_finetune.8.bias']\n",
      "2025-04-24 22:31:51,577 - Transformer - INFO - missing_keys\n",
      "2025-04-24 22:31:51,577 - Transformer - INFO - Some model parameters or buffers are not found in the checkpoint:\n",
      "  \u001b[34mencoder.first_conv.0.weight\u001b[0m\n",
      "  \u001b[34mpos_embed.0.weight\u001b[0m\n",
      "  \u001b[34mcls_head_finetune.8.{weight, bias}\u001b[0m\n",
      "2025-04-24 22:31:51,578 - Transformer - INFO - [Transformer] Successful Loading the ckpt from DAPT/checkpoints/modelnet.pth\n",
      "2025-04-24 22:31:54,567 - finetune_modelnet_dapt - INFO - Using Data parallel ...\n",
      "2025-04-24 22:31:54,574 - finetune_modelnet_dapt - INFO - >> Trainable Parameters:\n",
      "2025-04-24 22:31:54,576 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,577 - finetune_modelnet_dapt - INFO - |Name                                                                    |Dtype            |Shape          |#Params   |\n",
      "2025-04-24 22:31:54,577 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,578 - finetune_modelnet_dapt - INFO - |module.cls_token                                                        |torch.float32    |(1, 1, 384)    |384       |\n",
      "2025-04-24 22:31:54,579 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,579 - finetune_modelnet_dapt - INFO - |module.cls_pos                                                          |torch.float32    |(1, 1, 384)    |384       |\n",
      "2025-04-24 22:31:54,580 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,580 - finetune_modelnet_dapt - INFO - |module.tfts_gamma_1                                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,581 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,581 - finetune_modelnet_dapt - INFO - |module.tfts_beta_1                                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,582 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,587 - finetune_modelnet_dapt - INFO - |module.tfts_gamma_2                                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,588 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,588 - finetune_modelnet_dapt - INFO - |module.tfts_beta_2                                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,589 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,590 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,591 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,592 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,594 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,595 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,596 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,596 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,597 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,598 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,599 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,600 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,601 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,602 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,602 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,603 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,604 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,604 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,605 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,606 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,607 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,608 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,608 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,609 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,610 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,611 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,612 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,613 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,614 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,615 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,615 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,616 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,617 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,618 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,620 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,622 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,624 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,625 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,626 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,628 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,629 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,630 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,631 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,636 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.0.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,637 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,638 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,639 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,640 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,641 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,642 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,644 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,644 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,645 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,646 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,648 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,648 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,649 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,650 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,651 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,651 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,652 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,653 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,653 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,654 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,655 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,655 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,656 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,658 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,659 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,659 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,660 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,661 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,662 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,662 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,663 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,664 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,664 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,665 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,666 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,667 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,667 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,668 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,669 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,669 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,670 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,672 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,673 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,674 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.1.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,675 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,676 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,677 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,678 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,679 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,680 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,681 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,683 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,684 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,685 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,687 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,687 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,688 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,689 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,690 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,691 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,692 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,693 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,694 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,695 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,695 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,696 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,697 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,697 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,699 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,700 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,701 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,701 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,702 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,703 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,703 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,704 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,705 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,705 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,706 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,707 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,708 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,708 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,709 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,709 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,710 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,711 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,712 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,712 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.2.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,713 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,714 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,714 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,715 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,715 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,716 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,717 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,717 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,718 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,718 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,719 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,720 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,720 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,721 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,721 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,722 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,723 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,723 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,724 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,724 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,725 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,726 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,727 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,728 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,729 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,730 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,732 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,733 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,734 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,736 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,736 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,737 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,738 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,739 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,740 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,741 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,742 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,742 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,744 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,745 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,745 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,746 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,747 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,748 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.3.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,748 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,749 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,750 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,750 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,751 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,751 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,752 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,752 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,753 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,753 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,754 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,754 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,755 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,756 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,756 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,757 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,757 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,758 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,758 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,761 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,761 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,762 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,763 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,763 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,764 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,765 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,765 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,766 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,766 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,767 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,768 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,768 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,769 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,770 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,770 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,771 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,772 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,773 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,774 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): PointTransformer_DAPT(\n",
      "    (group_divider): Group(\n",
      "      (knn): KNN()\n",
      "    )\n",
      "    (encoder): Encoder(\n",
      "      (first_conv): Sequential(\n",
      "        (0): Conv1d(9, 128, kernel_size=(1,), stride=(1,))\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (second_conv): Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (pos_embed): Sequential(\n",
      "      (0): Linear(in_features=9, out_features=128, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Linear(in_features=128, out_features=384, bias=True)\n",
      "    )\n",
      "    (blocks): TransformerEncoder(\n",
      "      (blocks): ModuleList(\n",
      "        (0): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): Identity()\n",
      "          (drop_path2): Identity()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (1): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (2): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (3): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (4): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (5): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (6): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (7): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (8): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (9): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (10): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "        (11): Block(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path1): DropPath()\n",
      "          (drop_path2): DropPath()\n",
      "          (Adapter_MLP): Adapter(\n",
      "            (adapter_layer_norm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (scale): Linear(in_features=384, out_features=1, bias=True)\n",
      "            (down_proj): Linear(in_features=384, out_features=72, bias=True)\n",
      "            (non_linear_func): GELU()\n",
      "            (up_proj): Linear(in_features=72, out_features=384, bias=True)\n",
      "          )\n",
      "          (non_linear_func): GELU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (cls_head_finetune): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Dropout(p=0.5, inplace=False)\n",
      "      (8): Linear(in_features=256, out_features=2, bias=True)\n",
      "    )\n",
      "    (loss_ce): CrossEntropyLoss()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 22:31:54,775 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,776 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,777 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,777 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,778 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.4.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,779 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,780 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,781 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,782 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,783 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,783 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,784 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,785 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,786 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,786 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,787 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,789 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,789 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,790 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,790 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,791 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,792 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,792 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,793 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,793 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,795 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,796 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,797 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,798 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,799 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,800 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,801 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,802 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,803 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,805 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,806 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,807 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,808 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,810 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,811 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,812 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,813 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,813 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,814 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,815 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,817 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,817 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,818 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,818 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.5.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,820 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,820 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,821 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,821 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,822 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,823 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,824 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,825 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,826 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,827 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,827 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,828 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,829 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,830 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,831 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,832 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,832 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,833 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,833 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,834 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,835 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,836 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,837 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,837 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,838 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,839 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,840 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,840 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,841 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,842 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,842 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,843 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,844 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,845 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,845 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,846 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,846 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,847 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,848 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,848 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,849 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,850 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,850 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,851 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.6.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,851 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,852 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,853 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,853 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,854 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,854 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,855 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,856 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,856 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,857 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,857 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,858 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,859 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,859 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,860 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,860 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,861 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,861 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,862 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,862 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,863 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,863 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,864 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,865 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,865 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,866 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,866 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,867 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,867 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,868 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,869 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,869 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,870 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,870 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,871 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,872 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,873 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,873 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,874 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,875 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,876 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,877 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,877 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,878 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.7.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,879 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,883 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,884 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,884 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,885 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,887 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,888 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,889 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,889 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,890 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,892 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,892 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,893 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,894 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,894 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,895 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,896 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,896 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,897 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,898 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,900 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,901 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,901 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,902 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,903 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,903 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,904 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,904 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,906 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,906 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,907 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,908 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,909 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,909 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,910 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,914 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,915 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,916 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,917 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,917 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,918 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,918 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,919 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,920 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.8.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,921 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,921 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.tfts_gamma_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,922 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,923 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.tfts_beta_1                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,924 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,924 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.tfts_gamma_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,925 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,927 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.tfts_beta_2                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,928 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,929 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.tfts_gamma_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,930 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,931 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.tfts_beta_3                                      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,932 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,934 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.mlp.tfts_gamma_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,935 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,935 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.mlp.tfts_beta_1                                  |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,936 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,937 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.mlp.tfts_gamma_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,938 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,942 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.mlp.tfts_beta_2                                  |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,943 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,943 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.attn.tfts_gamma_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,944 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,946 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.attn.tfts_beta_1                                 |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,947 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,948 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.attn.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,948 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,949 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.attn.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,950 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,951 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.Adapter_MLP.adapter_layer_norm_before.weight     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,952 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,953 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.Adapter_MLP.adapter_layer_norm_before.bias       |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,956 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,957 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.Adapter_MLP.scale.weight                         |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,958 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,959 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.Adapter_MLP.scale.bias                           |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,960 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,961 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.Adapter_MLP.down_proj.weight                     |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,962 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,963 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.Adapter_MLP.down_proj.bias                       |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,964 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,965 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.Adapter_MLP.up_proj.weight                       |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,968 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,970 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.9.Adapter_MLP.up_proj.bias                         |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,970 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,971 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.tfts_gamma_1                                    |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,972 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,973 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.tfts_beta_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,974 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,975 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.tfts_gamma_2                                    |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,975 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,976 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.tfts_beta_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,977 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,977 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.tfts_gamma_3                                    |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,978 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,979 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.tfts_beta_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,980 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,980 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.mlp.tfts_gamma_1                                |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,981 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,982 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.mlp.tfts_beta_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:54,983 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,983 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.mlp.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,984 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,985 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.mlp.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,985 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,986 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.attn.tfts_gamma_1                               |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,987 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,987 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.attn.tfts_beta_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:54,988 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,989 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.attn.tfts_gamma_2                               |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,989 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,990 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.attn.tfts_beta_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,990 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,991 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.Adapter_MLP.adapter_layer_norm_before.weight    |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,992 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,992 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.Adapter_MLP.adapter_layer_norm_before.bias      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:54,993 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,994 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.Adapter_MLP.scale.weight                        |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:54,994 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,995 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.Adapter_MLP.scale.bias                          |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:54,995 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,996 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.Adapter_MLP.down_proj.weight                    |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:54,996 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,997 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.Adapter_MLP.down_proj.bias                      |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:54,997 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,998 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.Adapter_MLP.up_proj.weight                      |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:54,998 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:54,999 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.10.Adapter_MLP.up_proj.bias                        |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,000 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,000 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.tfts_gamma_1                                    |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,001 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,001 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.tfts_beta_1                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,002 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,003 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.tfts_gamma_2                                    |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,003 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,004 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.tfts_beta_2                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,004 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,005 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.tfts_gamma_3                                    |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,005 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,006 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.tfts_beta_3                                     |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,007 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,007 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.mlp.tfts_gamma_1                                |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:55,008 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,008 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.mlp.tfts_beta_1                                 |torch.float32    |(1536,)        |1536      |\n",
      "2025-04-24 22:31:55,009 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,009 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.mlp.tfts_gamma_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,010 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,011 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.mlp.tfts_beta_2                                 |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,012 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,012 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.attn.tfts_gamma_1                               |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:55,013 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,014 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.attn.tfts_beta_1                                |torch.float32    |(1152,)        |1152      |\n",
      "2025-04-24 22:31:55,014 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,015 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.attn.tfts_gamma_2                               |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,016 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,016 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.attn.tfts_beta_2                                |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,017 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,018 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.Adapter_MLP.adapter_layer_norm_before.weight    |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,018 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,019 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.Adapter_MLP.adapter_layer_norm_before.bias      |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,019 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,020 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.Adapter_MLP.scale.weight                        |torch.float32    |(1, 384)       |384       |\n",
      "2025-04-24 22:31:55,021 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,021 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.Adapter_MLP.scale.bias                          |torch.float32    |(1,)           |1         |\n",
      "2025-04-24 22:31:55,022 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,022 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.Adapter_MLP.down_proj.weight                    |torch.float32    |(72, 384)      |27648     |\n",
      "2025-04-24 22:31:55,023 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,024 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.Adapter_MLP.down_proj.bias                      |torch.float32    |(72,)          |72        |\n",
      "2025-04-24 22:31:55,024 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,025 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.Adapter_MLP.up_proj.weight                      |torch.float32    |(384, 72)      |27648     |\n",
      "2025-04-24 22:31:55,025 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,026 - finetune_modelnet_dapt - INFO - |module.blocks.blocks.11.Adapter_MLP.up_proj.bias                        |torch.float32    |(384,)         |384       |\n",
      "2025-04-24 22:31:55,026 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,027 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.0.weight                                       |torch.float32    |(256, 768)     |196608    |\n",
      "2025-04-24 22:31:55,027 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,028 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.0.bias                                         |torch.float32    |(256,)         |256       |\n",
      "2025-04-24 22:31:55,029 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,029 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.1.weight                                       |torch.float32    |(256,)         |256       |\n",
      "2025-04-24 22:31:55,030 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,031 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.1.bias                                         |torch.float32    |(256,)         |256       |\n",
      "2025-04-24 22:31:55,031 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,032 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.4.weight                                       |torch.float32    |(256, 256)     |65536     |\n",
      "2025-04-24 22:31:55,038 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,039 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.4.bias                                         |torch.float32    |(256,)         |256       |\n",
      "2025-04-24 22:31:55,039 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,040 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.5.weight                                       |torch.float32    |(256,)         |256       |\n",
      "2025-04-24 22:31:55,041 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,041 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.5.bias                                         |torch.float32    |(256,)         |256       |\n",
      "2025-04-24 22:31:55,042 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,042 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.8.weight                                       |torch.float32    |(2, 256)       |512       |\n",
      "2025-04-24 22:31:55,043 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,043 - finetune_modelnet_dapt - INFO - |module.cls_head_finetune.8.bias                                         |torch.float32    |(2,)           |2         |\n",
      "2025-04-24 22:31:55,044 - finetune_modelnet_dapt - INFO - -----------------------------------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:31:55,048 - finetune_modelnet_dapt - INFO - >> # TrainableParams:       \t1.06\tM  1059.95\tK\n",
      "2025-04-24 22:31:55,049 - finetune_modelnet_dapt - INFO - >> # NonTrainableParams:    \t21.83\tM\n",
      "2025-04-24 22:31:55,050 - finetune_modelnet_dapt - INFO - >> # TotalParams:           \t22.89\tM\n",
      "2025-04-24 22:31:55,050 - finetune_modelnet_dapt - INFO - >> # TuningRatio:           \t4.63\t%\n",
      "2025-04-24 22:31:55,051 - finetune_modelnet_dapt - INFO - \n",
      "\n",
      "2025-04-24 22:32:00,799 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 0 EpochTime = 5.746 (s) Losses = ['0.8350', '48.0000'] lr = 0.000010\n",
      "2025-04-24 22:32:01,010 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:03,637 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 1 EpochTime = 2.624 (s) Losses = ['0.8654', '45.6667'] lr = 0.000010\n",
      "2025-04-24 22:32:04,501 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 1  acc = 38.9068\n",
      "2025-04-24 22:32:04,719 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:04,721 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:04,961 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:07,509 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 2 EpochTime = 2.544 (s) Losses = ['0.8213', '48.3333'] lr = 0.000010\n",
      "2025-04-24 22:32:08,453 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 2  acc = 39.5498\n",
      "2025-04-24 22:32:08,659 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:08,660 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:08,881 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:11,497 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 3 EpochTime = 2.612 (s) Losses = ['0.8032', '49.3333'] lr = 0.000010\n",
      "2025-04-24 22:32:12,283 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 3  acc = 41.8006\n",
      "2025-04-24 22:32:12,491 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:12,493 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:12,713 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:15,361 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 4 EpochTime = 2.645 (s) Losses = ['0.7482', '53.6667'] lr = 0.000010\n",
      "2025-04-24 22:32:16,214 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 4  acc = 40.1929\n",
      "2025-04-24 22:32:16,439 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:19,150 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 5 EpochTime = 2.708 (s) Losses = ['0.8014', '51.6667'] lr = 0.000010\n",
      "2025-04-24 22:32:19,964 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 5  acc = 42.7653\n",
      "2025-04-24 22:32:20,208 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:20,210 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:20,430 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:22,972 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 6 EpochTime = 2.540 (s) Losses = ['0.8165', '49.0000'] lr = 0.000010\n",
      "2025-04-24 22:32:23,763 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 6  acc = 44.6945\n",
      "2025-04-24 22:32:23,986 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:23,987 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:24,208 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:26,938 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 7 EpochTime = 2.728 (s) Losses = ['0.7694', '50.0000'] lr = 0.000010\n",
      "2025-04-24 22:32:27,734 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 7  acc = 45.0161\n",
      "2025-04-24 22:32:27,942 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:27,943 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:28,161 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:30,749 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 8 EpochTime = 2.586 (s) Losses = ['0.7728', '53.0000'] lr = 0.000010\n",
      "2025-04-24 22:32:31,562 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 8  acc = 48.2315\n",
      "2025-04-24 22:32:31,784 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:31,786 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:31,994 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:34,553 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 9 EpochTime = 2.558 (s) Losses = ['0.7975', '48.3333'] lr = 0.000010\n",
      "2025-04-24 22:32:35,515 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 9  acc = 44.6945\n",
      "2025-04-24 22:32:35,730 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:38,410 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 10 EpochTime = 2.677 (s) Losses = ['0.8056', '50.0000'] lr = 0.000010\n",
      "2025-04-24 22:32:39,224 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 10  acc = 46.6238\n",
      "2025-04-24 22:32:39,436 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:42,086 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 11 EpochTime = 2.648 (s) Losses = ['0.7704', '53.6667'] lr = 0.000010\n",
      "2025-04-24 22:32:42,888 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 11  acc = 46.6238\n",
      "2025-04-24 22:32:43,098 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:45,753 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 12 EpochTime = 2.653 (s) Losses = ['0.8144', '53.0000'] lr = 0.000010\n",
      "2025-04-24 22:32:46,588 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 12  acc = 51.7685\n",
      "2025-04-24 22:32:46,826 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:46,828 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:47,051 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:49,613 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 13 EpochTime = 2.560 (s) Losses = ['0.7521', '53.0000'] lr = 0.000010\n",
      "2025-04-24 22:32:50,449 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 13  acc = 47.2669\n",
      "2025-04-24 22:32:50,689 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:53,280 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 14 EpochTime = 2.587 (s) Losses = ['0.7599', '50.6667'] lr = 0.000010\n",
      "2025-04-24 22:32:54,188 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 14  acc = 53.0547\n",
      "2025-04-24 22:32:54,399 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:54,400 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:54,628 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:32:57,214 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 15 EpochTime = 2.585 (s) Losses = ['0.8130', '46.3333'] lr = 0.000010\n",
      "2025-04-24 22:32:58,084 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 15  acc = 54.0193\n",
      "2025-04-24 22:32:58,324 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:32:58,325 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:32:58,534 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:01,227 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 16 EpochTime = 2.692 (s) Losses = ['0.7786', '51.0000'] lr = 0.000010\n",
      "2025-04-24 22:33:02,066 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 16  acc = 53.3762\n",
      "2025-04-24 22:33:02,284 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:04,957 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 17 EpochTime = 2.671 (s) Losses = ['0.7749', '54.6667'] lr = 0.000010\n",
      "2025-04-24 22:33:05,819 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 17  acc = 56.2701\n",
      "2025-04-24 22:33:06,059 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:33:06,061 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:33:06,287 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:08,966 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 18 EpochTime = 2.676 (s) Losses = ['0.7092', '58.3333'] lr = 0.000010\n",
      "2025-04-24 22:33:09,867 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 18  acc = 53.3762\n",
      "2025-04-24 22:33:10,082 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:12,705 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 19 EpochTime = 2.621 (s) Losses = ['0.7960', '51.0000'] lr = 0.000010\n",
      "2025-04-24 22:33:13,551 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 19  acc = 55.6270\n",
      "2025-04-24 22:33:13,768 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:16,474 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 20 EpochTime = 2.704 (s) Losses = ['0.7969', '47.0000'] lr = 0.000010\n",
      "2025-04-24 22:33:17,374 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 20  acc = 57.8778\n",
      "2025-04-24 22:33:17,593 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:33:17,595 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:33:17,801 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:20,469 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 21 EpochTime = 2.666 (s) Losses = ['0.7180', '59.3333'] lr = 0.000010\n",
      "2025-04-24 22:33:21,434 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 21  acc = 59.1640\n",
      "2025-04-24 22:33:21,656 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:33:21,658 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:33:21,871 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:24,442 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 22 EpochTime = 2.568 (s) Losses = ['0.7901', '52.6667'] lr = 0.000010\n",
      "2025-04-24 22:33:25,256 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 22  acc = 59.1640\n",
      "2025-04-24 22:33:25,478 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:28,088 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 23 EpochTime = 2.607 (s) Losses = ['0.7688', '55.3333'] lr = 0.000010\n",
      "2025-04-24 22:33:29,043 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 23  acc = 60.1286\n",
      "2025-04-24 22:33:29,263 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:33:29,264 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:33:29,466 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:32,194 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 24 EpochTime = 2.725 (s) Losses = ['0.7915', '52.3333'] lr = 0.000010\n",
      "2025-04-24 22:33:33,004 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 24  acc = 61.0932\n",
      "2025-04-24 22:33:33,231 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\n",
      "2025-04-24 22:33:33,232 - finetune_modelnet_dapt - INFO - --------------------------------------------------------------------------------------------\n",
      "2025-04-24 22:33:33,447 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:36,174 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 25 EpochTime = 2.724 (s) Losses = ['0.7431', '55.6667'] lr = 0.000010\n",
      "2025-04-24 22:33:37,023 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 25  acc = 60.7717\n",
      "2025-04-24 22:33:37,242 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:39,981 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 26 EpochTime = 2.736 (s) Losses = ['0.7854', '51.0000'] lr = 0.000010\n",
      "2025-04-24 22:33:40,802 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 26  acc = 59.8071\n",
      "2025-04-24 22:33:41,004 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:43,541 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 27 EpochTime = 2.534 (s) Losses = ['0.7743', '54.6667'] lr = 0.000010\n",
      "2025-04-24 22:33:44,382 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 27  acc = 59.8071\n",
      "2025-04-24 22:33:44,587 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:47,261 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 28 EpochTime = 2.672 (s) Losses = ['0.7578', '58.0000'] lr = 0.000010\n",
      "2025-04-24 22:33:48,195 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 28  acc = 60.7717\n",
      "2025-04-24 22:33:48,400 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:50,936 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 29 EpochTime = 2.534 (s) Losses = ['0.7729', '54.6667'] lr = 0.000010\n",
      "2025-04-24 22:33:51,771 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 29  acc = 61.0932\n",
      "2025-04-24 22:33:51,989 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:54,579 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 30 EpochTime = 2.588 (s) Losses = ['0.7504', '54.6667'] lr = 0.000010\n",
      "2025-04-24 22:33:55,482 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 30  acc = 60.4502\n",
      "2025-04-24 22:33:55,694 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n",
      "2025-04-24 22:33:58,476 - finetune_modelnet_dapt - INFO - [Training] EPOCH: 31 EpochTime = 2.781 (s) Losses = ['0.7535', '56.6667'] lr = 0.000010\n",
      "2025-04-24 22:33:59,312 - finetune_modelnet_dapt - INFO - [Validation] EPOCH: 31  acc = 61.0932\n",
      "2025-04-24 22:33:59,539 - finetune_modelnet_dapt - INFO - Save checkpoint at ./experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-last.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m dapt_args\u001b[38;5;241m.\u001b[39mdistributed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dapt_args\u001b[38;5;241m.\u001b[39mckpts \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDAPT/checkpoints/modelnet.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrunner_finetune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_net_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdapt_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CS-UY_3943_neuro/density_decoding/DAPT/tools/runner_finetune.py:164\u001b[0m, in \u001b[0;36mrun_net_core\u001b[0;34m(args, config, train_dataloader, test_dataloader, train_sampler, train_writer, val_writer)\u001b[0m\n\u001b[1;32m    162\u001b[0m _loss \u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mdetect_anomaly():\n\u001b[0;32m--> 164\u001b[0m     \u001b[43m_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_iter \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39mstep_per_update:\n",
      "File \u001b[0;32m~/miniconda3/envs/cs-uy_3943_neuro/lib/python3.9/site-packages/torch/tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    238\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    239\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    244\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 245\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs-uy_3943_neuro/lib/python3.9/site-packages/torch/autograd/__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 145\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dapt_args.use_gpu = True\n",
    "dapt_args.distributed = False\n",
    "dapt_args.ckpts = \"DAPT/checkpoints/modelnet.pth\"\n",
    "runner_finetune.run_net_core(dapt_args, config, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "636010c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 23:58:21,033 - finetune_modelnet_dapt - INFO - Tester start ... \n",
      "2025-04-11 23:58:21,206 - finetune_modelnet_dapt - INFO - Loading weights from experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth...\n",
      "2025-04-11 23:58:21,308 - finetune_modelnet_dapt - INFO - ckpts @ 72 epoch( performance = {'acc': tensor(64.3087)})\n",
      "2025-04-11 23:58:22,299 - finetune_modelnet_dapt - INFO - [TEST] inference time: 0.05661245187123617\n",
      "2025-04-11 23:58:22,305 - finetune_modelnet_dapt - INFO - [TEST] acc = 59.8071, f1 = 0.7300, auc = 0.5050\n"
     ]
    }
   ],
   "source": [
    "dapt_args.use_gpu = True\n",
    "dapt_args.distributed = False\n",
    "dapt_args.ckpts = \"experiments/finetune_modelnet_dapt/cfgs/debug/ckpt-best.pth\"\n",
    "runner_finetune.test_net_core(dapt_args, config, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs-uy_3943_neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
