{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a3a3c6-c029-486d-9a9b-d3bc1cf7c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "\n",
    "import isosplit\n",
    "\n",
    "from clusterless import preprocess\n",
    "from clusterless import decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c83eddd-64ec-44da-91f6-be3c8880cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "804affc9-ffa2-4b40-98c1-e33a5fc928db",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 25\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)         \n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     \n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE) \n",
    "plt.rc('axes', linewidth = 1.5)\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)   \n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)   \n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   \n",
    "plt.rc('figure', titlesize=MEDIUM_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779810ad-6236-439a-9c42-920935cc363c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd1c562-85c3-4d92-98da-b1ae930d9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = 'febb430e-2d50-4f83-87a0-b5ffbb9a4943'\n",
    "rootpath = '/mnt/3TB/yizi/Downloads/ONE/openalyx.internationalbrainlab.org'\n",
    "trial_data_path = rootpath + '/danlab/Subjects/DY_009/2020-02-27/001/alf'\n",
    "neural_data_path = '/mnt/3TB/yizi/danlab/Subjects/DY_009'\n",
    "behavior_data_path = rootpath + '/paper_repro_ephys_data/figure9_10/original_data'\n",
    "save_path = '../saved_results/danlab/Subjects/DY_009'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f1f05f-1250-40a9-8b16-88469fef6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = 'lp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d94ef8-0d09-4bb5-9342-3179e7c0ba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: febb430e-2d50-4f83-87a0-b5ffbb9a4943\n",
      "eid: db4df448-e449-4a6f-a0e7-288711e7a75a\n",
      "found 85 good ibl units ..\n",
      "1st trial stim on time: 40.81, last trial stim on time 2252.10\n",
      "found 74 neurons in region lp ...\n",
      "found 38 channels in region lp ...\n"
     ]
    }
   ],
   "source": [
    "sorted_trials, good_sorted_trials, unsorted_trials, stim_on_times, np1_channel_map= preprocess.load_neural_data(\n",
    "    pid=pid, \n",
    "    trial_data_path=trial_data_path,\n",
    "    neural_data_path=neural_data_path,\n",
    "    behavior_data_path=behavior_data_path,\n",
    "    keep_active_trials=True, \n",
    "    # roi='all',\n",
    "    roi = roi,\n",
    "    kilosort=True,\n",
    "    triage=False,\n",
    "    good_units=True,\n",
    "    thresholding=True\n",
    ")\n",
    "\n",
    "behave_dict = preprocess.load_behaviors_data(behavior_data_path, pid)\n",
    "motion_energy, wheel_velocity, wheel_speed, paw_speed, nose_speed, pupil_diameter = preprocess.preprocess_dynamic_behaviors(behave_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da5cbb8-4cf4-45c4-a61e-97c97bf63423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, data, y, stim_on_times, np1_channel_map, n_t_bins=30):\n",
    "        self.data = data\n",
    "        self.y = y\n",
    "        self.stim_on_times = stim_on_times\n",
    "        self.np1_channel_map = np1_channel_map\n",
    "        self.n_t_bins = n_t_bins\n",
    "        self.n_trials = stim_on_times.shape[0]\n",
    "        self.n_channels = np1_channel_map.shape[0]\n",
    "        self.t_binning = np.arange(0, 1.5, step = (1.5 - 0) / n_t_bins)\n",
    "        self.rand_trial_ids = np.arange(self.n_trials)\n",
    "        \n",
    "        # allocate unsorted data into trials\n",
    "        self.trial_ids = []\n",
    "        self.t_ids = []\n",
    "        self.trials = []\n",
    "        self.t_bins = []\n",
    "        for k in range(self.n_trials):\n",
    "            mask = np.logical_and(data[:,0] >= stim_on_times[k] - 0.5,\n",
    "                                  data[:,0] <= stim_on_times[k] + 1)\n",
    "            trial = data[mask,:]\n",
    "            trial[:,0] = trial[:,0] - trial[:,0].min()\n",
    "            t_bins = np.digitize(trial[:,0], self.t_binning, right = False) - 1\n",
    "            t_bin_lst = []\n",
    "            for t in range(self.n_t_bins):\n",
    "                t_bin = trial[t_bins == t,1:]\n",
    "                self.trial_ids.append(np.ones_like(t_bin[:,0]) * k)\n",
    "                self.t_ids.append(np.ones_like(t_bin[:,0]) * t)\n",
    "                t_bin_lst.append(t_bin)\n",
    "            self.trials.append(t_bin_lst)\n",
    "    \n",
    "    \n",
    "    def split_train_test(self, train_ids, test_ids):\n",
    "        \n",
    "        self.train_ids = self.rand_trial_ids[train_ids]\n",
    "        self.test_ids = self.rand_trial_ids[test_ids]\n",
    "        self.y_train = self.y[self.train_ids]\n",
    "        self.y_test = self.y[self.test_ids]\n",
    "        \n",
    "        trial_ids = np.concatenate(self.trial_ids)\n",
    "        t_ids = np.concatenate(self.t_ids)\n",
    "        trials = np.concatenate(np.concatenate(self.trials))\n",
    "\n",
    "        train_mask = np.sum([trial_ids == idx for idx in self.train_ids], axis=0).astype(bool)\n",
    "        test_mask = np.sum([trial_ids == idx for idx in self.test_ids], axis=0).astype(bool)\n",
    "        train_trial_ids, test_trial_ids = trial_ids[train_mask], trial_ids[test_mask]\n",
    "        train_t_ids, test_t_ids = t_ids[train_mask], t_ids[test_mask]\n",
    "        train_trials, test_trials = trials[train_mask], trials[test_mask]\n",
    "        \n",
    "        return train_trials, train_trial_ids, train_t_ids, \\\n",
    "               test_trials, test_trial_ids, test_t_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a170e94-7388-43ae-8367-f680c532cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(data = np.concatenate(unsorted_trials)[:,[0,1,2,3,4]], \n",
    "                         y = wheel_velocity, \n",
    "                         stim_on_times = stim_on_times, \n",
    "                         np1_channel_map = np1_channel_map, \n",
    "                         n_t_bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a9abac-d7de-40fc-ac4a-27aaaa18da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# kf = KFold(n_splits=5, shuffle=False)\n",
    "kf_train_ids = []; kf_test_ids = []\n",
    "for i, (train_ids, test_ids) in enumerate(kf.split(data_loader.y)):\n",
    "    kf_train_ids.append(train_ids)\n",
    "    kf_test_ids.append(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b5143bd-bd3d-4f59-b420-f83402c51a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "train_trials, train_trial_ids, train_t_ids, \\\n",
    "test_trials, test_trial_ids, test_t_ids = data_loader.split_train_test(\n",
    "    train_ids = kf_train_ids[i], test_ids = kf_test_ids[i]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30d5815-3716-476f-96eb-fb91968e7935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel 170.0 has 2 modes ...\n",
      "channel 171.0 has 1 modes ...\n",
      "channel 172.0 has 2 modes ...\n",
      "channel 173.0 has 2 modes ...\n",
      "channel 174.0 has 1 modes ...\n",
      "channel 177.0 has 1 modes ...\n",
      "channel 178.0 has 2 modes ...\n",
      "channel 179.0 has 2 modes ...\n",
      "channel 180.0 has 1 modes ...\n",
      "channel 181.0 has 1 modes ...\n",
      "channel 182.0 has 1 modes ...\n",
      "channel 183.0 has 1 modes ...\n",
      "channel 184.0 has 1 modes ...\n",
      "channel 185.0 has 2 modes ...\n",
      "channel 186.0 has 2 modes ...\n",
      "channel 187.0 has 1 modes ...\n",
      "channel 189.0 has 1 modes ...\n",
      "channel 190.0 has 2 modes ...\n",
      "channel 191.0 has 1 modes ...\n",
      "channel 192.0 has 2 modes ...\n",
      "channel 194.0 has 3 modes ...\n",
      "channel 195.0 has 1 modes ...\n",
      "channel 196.0 has 1 modes ...\n",
      "channel 197.0 has 1 modes ...\n",
      "channel 198.0 has 1 modes ...\n",
      "channel 199.0 has 1 modes ...\n",
      "channel 200.0 has 1 modes ...\n",
      "channel 201.0 has 1 modes ...\n",
      "channel 202.0 has 2 modes ...\n",
      "channel 204.0 has 2 modes ...\n",
      "channel 205.0 has 1 modes ...\n",
      "channel 206.0 has 1 modes ...\n"
     ]
    }
   ],
   "source": [
    "sub_weights_lst = []\n",
    "sub_means_lst = []\n",
    "sub_covs_lst = []\n",
    "\n",
    "all_trials = np.vstack([train_trials, test_trials])\n",
    "for channel in np.unique(all_trials[:,0]):\n",
    "    sub_s = all_trials[all_trials[:,0] == channel, 1:]\n",
    "    \n",
    "    if sub_s.shape[0] > 10:\n",
    "        isosplit_labels = isosplit.isosplit(sub_s.T, K_init=20, min_cluster_size=10,\n",
    "                                            whiten_cluster_pairs=1, refine_clusters=1)\n",
    "    # if sub_s.shape[0] > 5:\n",
    "    #     isosplit_labels = isosplit.isosplit(sub_s.T, K_init=20, min_cluster_size=5,\n",
    "    #                                         whiten_cluster_pairs=1, refine_clusters=1)\n",
    "    elif sub_s.shape[0] < 2:\n",
    "        continue\n",
    "    else:\n",
    "        sub_gmm = GaussianMixture(n_components=1, \n",
    "                              covariance_type='full',\n",
    "                              init_params='k-means++', \n",
    "                              verbose=0)\n",
    "        sub_gmm.fit(sub_s)\n",
    "        sub_labels = sub_gmm.predict(sub_s)\n",
    "        sub_weights = len(sub_labels)/len(all_trials)\n",
    "        sub_weights_lst.append(sub_weights)\n",
    "        sub_means_lst.append(sub_gmm.means_)\n",
    "        sub_covs_lst.append(sub_gmm.covariances_)\n",
    "        continue\n",
    "    \n",
    "    n_splits = np.unique(isosplit_labels).shape[0]\n",
    "    print(f'channel {channel} has {n_splits} modes ...')\n",
    "    \n",
    "    if n_splits == 1: \n",
    "        sub_gmm = GaussianMixture(n_components=1, \n",
    "                              covariance_type='full',\n",
    "                              init_params='k-means++', \n",
    "                              verbose=0)\n",
    "        sub_gmm.fit(sub_s)\n",
    "        sub_labels = sub_gmm.predict(sub_s)\n",
    "        sub_weights = len(sub_labels)/len(all_trials)\n",
    "        sub_weights_lst.append(sub_weights)\n",
    "        sub_means_lst.append(sub_gmm.means_)\n",
    "        sub_covs_lst.append(sub_gmm.covariances_)\n",
    "    else:\n",
    "        for label in np.arange(n_splits):\n",
    "            mask = isosplit_labels == label\n",
    "            sub_gmm = GaussianMixture(n_components=1, \n",
    "                              covariance_type='full',\n",
    "                              init_params='k-means++', \n",
    "                              verbose=0)\n",
    "            sub_gmm.fit(sub_s[mask])\n",
    "            sub_labels = sub_gmm.predict(sub_s[mask])\n",
    "            sub_weights = len(sub_labels)/len(all_trials)\n",
    "            sub_weights_lst.append(sub_weights)\n",
    "            sub_means_lst.append(sub_gmm.means_)\n",
    "            sub_covs_lst.append(sub_gmm.covariances_)\n",
    "            \n",
    "sub_weights = np.hstack(sub_weights_lst)\n",
    "sub_means = np.vstack(sub_means_lst)\n",
    "sub_covs = np.vstack(sub_covs_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab6f4f-8f41-44fe-9d71-caf0ec38132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_s_lst = []\n",
    "# sub_weights_lst = []\n",
    "# sub_means_lst = []\n",
    "# sub_covs_lst = []\n",
    "# for channel in np.unique(train_trials[:,0]):\n",
    "#     sub_s = train_trials[train_trials[:,0] == channel, 1:]\n",
    "#     sub_s_lst.append(sub_s)\n",
    "#     if len(sub_s) > 1:\n",
    "#         sub_gmm = GaussianMixture(n_components=1, \n",
    "#                           covariance_type='full',\n",
    "#                           init_params='k-means++', verbose=0)\n",
    "#         sub_gmm.fit(sub_s)\n",
    "#         sub_labels = sub_gmm.predict(sub_s)\n",
    "#         sub_weights = len(sub_s)/len(train_trials)\n",
    "#         sub_weights_lst.append(sub_weights)\n",
    "#         sub_means_lst.append(sub_gmm.means_)\n",
    "#         sub_covs_lst.append(sub_gmm.covariances_)\n",
    "        \n",
    "# sub_weights = np.hstack(sub_weights_lst)\n",
    "# sub_means = np.vstack(sub_means_lst)\n",
    "# sub_covs = np.vstack(sub_covs_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c71ad14-8a99-432f-bcc3-784062f90886",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=len(sub_weights), covariance_type='full', init_params='k-means++')\n",
    "gmm.weights_ = sub_weights\n",
    "gmm.means_ = sub_means\n",
    "gmm.covariances_ = sub_covs\n",
    "gmm.precisions_cholesky_ = np.linalg.cholesky(np.linalg.inv(sub_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484aa0b-7a3d-482a-ae88-0ba05c2ca98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm = GaussianMixture(n_components=100, \n",
    "#                       covariance_type='full', \n",
    "#                       init_params='k-means++',\n",
    "#                       verbose=0)\n",
    "# gmm.fit(train_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ea3b25d-4b85-4a19-850c-e2f17ac7b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor(train_trials[:,1:])\n",
    "y = torch.tensor(data_loader.y)\n",
    "ks = torch.tensor(train_trial_ids)\n",
    "ts = torch.tensor(train_t_ids)\n",
    "\n",
    "Nk = len(data_loader.train_ids)\n",
    "Nt = data_loader.n_t_bins\n",
    "Nc = gmm.means_.shape[0]\n",
    "Nd = gmm.means_.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eabf2359-e97b-4156-b9d5-b4deb23146e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54db6c-22c2-4ac2-914a-3080c28a3f91",
   "metadata": {},
   "source": [
    "#### CAVI-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "492ce76e-fa9c-468e-a939-4f42136ff111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_log(x, minval=1e-10):\n",
    "    return torch.log(x + minval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f1111f2-813f-490f-9320-11305244d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAVI(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, Nk, Nt, Nc, Nd, init_means, init_covs):\n",
    "        super(CAVI, self).__init__()\n",
    "        self.Nk = Nk\n",
    "        self.Nt = Nt\n",
    "        self.Nc = Nc\n",
    "        self.Nd = Nd\n",
    "        self.ks = ks\n",
    "        self.ts = ts\n",
    "        \n",
    "        # initialize variables for variational distribution\n",
    "        self.means = torch.nn.Parameter(torch.tensor(init_means), requires_grad=False)\n",
    "        self.covs = torch.nn.Parameter(torch.tensor(init_covs), requires_grad=False)\n",
    "        self.bs = torch.nn.Parameter(torch.randn((Nc)))\n",
    "        self.betas = torch.nn.Parameter(torch.randn((Nc, Nt)))\n",
    "\n",
    "        \n",
    "    def forward(self, s, y, ks, ts):\n",
    "        \n",
    "        # compute log-lambdas\n",
    "        log_lambdas = torch.zeros((self.Nk, self.Nc, self.Nt))\n",
    "        for k in range(self.Nk):\n",
    "            for t in range(self.Nt):\n",
    "                log_lambdas[k,:,t] = self.bs + self.betas[:,t] * y[k][t]\n",
    "                \n",
    "        \n",
    "        # compute mixing proportions \n",
    "        log_pis = log_lambdas - torch.logsumexp(log_lambdas, 1)[:,None,:]\n",
    "        \n",
    "        # compute log-likelihood\n",
    "        ll = torch.zeros((s.shape[0], self.Nc))\n",
    "        for j in range(self.Nc):\n",
    "            ll[:,j] = D.multivariate_normal.MultivariateNormal(\n",
    "                            loc=self.means[j], \n",
    "                            covariance_matrix=self.covs[j]\n",
    "                        ).log_prob(s)\n",
    "            \n",
    "        \n",
    "        # order of update is: E step -> compute ELBO -> M step\n",
    "        # E step\n",
    "        r = torch.zeros((s.shape[0], self.Nc))\n",
    "        for k in range(self.Nk):\n",
    "            for t in range(self.Nt):\n",
    "                k_t_idx = torch.logical_and(ks == torch.unique(ks).int()[k], ts == t)\n",
    "                r[k_t_idx] = torch.exp( ll[k_t_idx] + log_pis[k,:,t] )\n",
    "                r[k_t_idx] = r[k_t_idx] / r[k_t_idx].sum(1)[:,None]\n",
    "                \n",
    "                    \n",
    "        # compute ELBO\n",
    "        elbo_1 = 0; elbo_2 = 0; elbo_3 = 0\n",
    "        elbo = 0\n",
    "        for k in range(self.Nk):\n",
    "            for t in range(self.Nt):\n",
    "                k_t_idx = torch.logical_and(ks == torch.unique(ks).int()[k], ts == t)\n",
    "                elbo_1 += torch.sum( r[k_t_idx] * ll[k_t_idx] )\n",
    "                elbo_2 += torch.sum( r[k_t_idx] * log_pis[k,:,t] )\n",
    "                elbo_3 -= torch.sum( r[k_t_idx] * safe_log(r[k_t_idx]) )\n",
    "                \n",
    "                \n",
    "        # M step is done via back propagation\n",
    "                \n",
    "        return elbo_1 + elbo_2 + elbo_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ebe5bce-0f81-4b88-91af-5ebc6f6b5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 6\n",
    "batch_size = 1\n",
    "batch_ids = list(zip(*(iter(data_loader.train_ids),) * batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff3b3c74-68d0-44f3-8a79-b019d37793bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cavi = CAVI(batch_size, Nt, Nc, Nd, gmm.means_, gmm.covariances_)\n",
    "optim = torch.optim.Adam(cavi.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b92bc-5dfa-4b9c-a2bf-c6d30a8a07f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 batch 100\n",
      "iter: 1 total elbo: -537054.06\n",
      "iter: 2 batch 100\n",
      "iter: 2 total elbo: -511927.68\n",
      "iter: 3 batch 100\n",
      "iter: 3 total elbo: -505198.13\n",
      "iter: 4 batch 100\n",
      "iter: 4 total elbo: -503368.77\n",
      "iter: 5 batch 100\n",
      "iter: 5 total elbo: -502816.78\n",
      "iter: 6 batch 100\n",
      "iter: 6 total elbo: -502643.00\n",
      "iter: 7 batch 100\n",
      "iter: 7 total elbo: -502570.67\n",
      "iter: 8 batch 100\n",
      "iter: 8 total elbo: -502532.88\n",
      "iter: 9 batch 100\n",
      "iter: 9 total elbo: -502510.28\n",
      "iter: 10 batch 100\n",
      "iter: 10 total elbo: -502495.37\n",
      "iter: 11 batch 100\n",
      "iter: 11 total elbo: -502484.63\n",
      "iter: 12 batch 100\n",
      "iter: 12 total elbo: -502476.26\n",
      "iter: 13 batch 100\n",
      "iter: 13 total elbo: -502469.29\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_iter = 100\n",
    "elbos = []\n",
    "N = s.shape[0]\n",
    "for i in range(max_iter):\n",
    "    tot_elbo = 0\n",
    "    for n, batch_idx in enumerate(batch_ids): \n",
    "        mask = torch.logical_and(ks >= batch_idx[0], ks <= batch_idx[-1])\n",
    "        batch_s = s[mask]\n",
    "        batch_y = y[list(batch_idx)]\n",
    "        batch_ks = ks[mask]\n",
    "        batch_ts = ts[mask]\n",
    "        batch_elbo = cavi(batch_s, batch_y, batch_ks, batch_ts)\n",
    "        tot_elbo += batch_elbo\n",
    "        loss = - batch_elbo\n",
    "        loss.backward()\n",
    "        if (n+1) % 100 == 0:\n",
    "            print(f'iter: {i+1} batch {n+1}')\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "    print(f'iter: {i+1} total elbo: {tot_elbo:.2f}')\n",
    "    elbos.append(tot_elbo.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82095003-f54d-4b03-a4ee-15642116a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "elbos = [elbo for elbo in elbos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079c2c6-e52f-411c-90e7-d3aa801e1201",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2))\n",
    "plt.plot(elbos)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"ELBO\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb15cc9-efcb-45f8-a35e-e83f6eeca259",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lambdas = torch.zeros((Nk, Nc, Nt))\n",
    "for k in range(Nk):\n",
    "    for t in range(Nt):\n",
    "        log_lambdas[k,:,t] = cavi.bs + cavi.betas[:,t] * y[k][t]\n",
    "\n",
    "log_pis = log_lambdas - torch.logsumexp(log_lambdas, 1)[:,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3332c075-0d43-4e7e-b58e-550a25717447",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.imshow(torch.exp(log_pis.mean(0)).detach().numpy(), \n",
    "           aspect='auto', cmap='cubehelix')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d830d7-8ec4-4fd5-82a5-32e83a71b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(cavi.betas[-1,:].detach().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b889923-398e-4bcf-9ae7-5c68ac3fcc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccef1f4-77da-4d5b-9c55-484ea773e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cavi.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "578669c5-2879-4329-874d-fc0741d4df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_y_enc_res = {\n",
    "    'bs': cavi.bs,\n",
    "    'betas': cavi.betas,\n",
    "    'means': cavi.means,\n",
    "    'covs': cavi.covs\n",
    "}\n",
    "np.save(save_path + f'dy009_cont_y_enc_res_c{len(cavi.means)}.npy', cont_y_enc_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b034a422-b578-437c-8995-ce9f257baace",
   "metadata": {},
   "source": [
    "#### MoG only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f69e95-d913-4d46-a2c7-ca8da37bf755",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials = np.concatenate(np.concatenate(data_loader.trials))[:,1:]\n",
    "spike_times = data_loader.data[:,0]\n",
    "\n",
    "spike_labels = []\n",
    "spike_probs = []\n",
    "spike_labels.extend(gmm.predict(all_trials))\n",
    "spike_probs.extend(gmm.predict_proba(all_trials))\n",
    "spike_labels = np.array(spike_labels)\n",
    "spike_probs = np.array(spike_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d23492-d63b-409b-b40e-e9604b044406",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_gmm = preprocess.compute_neural_activity(\n",
    "    (spike_times, spike_labels, spike_probs),\n",
    "    data_loader.stim_on_times,\n",
    "    'clusterless', \n",
    "    n_time_bins=data_loader.n_t_bins\n",
    ")\n",
    "print(enc_gmm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65719e8c-79f5-4c0f-992d-40bba4944f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_loader.train_ids\n",
    "test = data_loader.test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f1551-d910-4273-abe4-eeb92f4aaa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = enc_gmm.reshape(-1, enc_gmm.shape[1] * enc_gmm.shape[2])[train]\n",
    "x_test = enc_gmm.reshape(-1, enc_gmm.shape[1] * enc_gmm.shape[2])[test]\n",
    "y_train = data_loader.y[train]\n",
    "\n",
    "ridge = Ridge(alpha=2000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_hat = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6003d-9275-42c0-9935-3a7c35c25d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), y_hat.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc4738-c384-4c1d-989e-abc745f800cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ExpSineSquared, RationalQuadratic, RBF\n",
    "\n",
    "long_term_trend_kernel = 50.0**2 * RBF(length_scale=50.0)\n",
    "seasonal_kernel = (\n",
    "    2.0**2\n",
    "    * RBF(length_scale=100.0)\n",
    "    * ExpSineSquared(length_scale=1.0, periodicity=1.0, periodicity_bounds=\"fixed\")\n",
    ")\n",
    "# irregularities_kernel = 0.5**2 * RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "# noise_kernel = 0.1**2 * RBF(length_scale=0.1) + WhiteKernel(\n",
    "#     noise_level=0.1**2, noise_level_bounds=(1e-5, 1e5)\n",
    "# )\n",
    "kernel = (\n",
    "    long_term_trend_kernel #+ seasonal_kernel + noise_kernel #+ irregularities_kernel \n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, alpha=1e-10)\n",
    "start_time = time.time()\n",
    "gaussian_process.fit(x_train, y_train)\n",
    "print(\n",
    "    f\"Time for GaussianProcessRegressor fitting: {time.time() - start_time:.3f} seconds\"\n",
    ")\n",
    "gp_pred = gaussian_process.predict(x_test)\n",
    "print(f'R2 = {r2_score(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), gp_pred.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba48647-cb49-46d8-87c6-a09b25787c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(data_loader.y[test].flatten()[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(gp_pred.flatten()[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc7666-b82a-4f9d-acb1-697baa81c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_enc_gmm, half_window_size, n_windows = decoder.sliding_window(\n",
    "    enc_gmm, \n",
    "    data_loader.n_trials,\n",
    "    window_size = 7\n",
    ")\n",
    "windowed_y = data_loader.y[:,half_window_size:n_windows].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561ff5a-a9fb-418a-ac9b-ac4abdb9fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_by_trial = windowed_enc_gmm.reshape((data_loader.n_trials, -1))\n",
    "y_by_trial = windowed_y.reshape((data_loader.n_trials, -1))\n",
    "x_train, x_test = x_by_trial[train], x_by_trial[test]\n",
    "y_train, y_test = y_by_trial[train], y_by_trial[test]\n",
    "\n",
    "x_train = x_train.reshape((-1, windowed_enc_gmm.shape[1]))\n",
    "x_test = x_test.reshape((-1, windowed_enc_gmm.shape[1]))\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "ridge = Ridge(alpha=10000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e9930-8dc2-4efa-a9eb-11b2cab4f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(y_test, y_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(y_test, y_pred):.3f}')\n",
    "print(f'corr = {pearsonr(y_test, y_pred).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608674f-fb36-487b-bd91-9897e9b3928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(y_test[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(y_pred[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa711a18-f5f6-47df-ae74-8ddb19984825",
   "metadata": {},
   "source": [
    "#### encoding MoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2347405d-b07e-425c-b017-b77fffe13df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = stim_on_times.shape[0]\n",
    "unsorted = np.vstack([unsorted_trials[i] for i in np.arange(n_trials)]) \n",
    "spike_times = unsorted[:,0]\n",
    "spike_channels = unsorted[:,1]\n",
    "spike_features = unsorted[:,2:]\n",
    "\n",
    "thresholded_neural_data = preprocess.compute_neural_activity(\n",
    "    (spike_times, spike_channels),\n",
    "    stim_on_times,\n",
    "    'thresholded', \n",
    "    n_time_bins=30,\n",
    "    regional=True\n",
    ")\n",
    "print(f'thresholded neural data shape: {thresholded_neural_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4400ff52-7891-4d6e-997e-debbfd1029d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = thresholded_neural_data.reshape(-1, thresholded_neural_data.shape[1] * thresholded_neural_data.shape[2])[train]\n",
    "x_test = thresholded_neural_data.reshape(-1, thresholded_neural_data.shape[1] * thresholded_neural_data.shape[2])[test]\n",
    "y_train = data_loader.y[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea665d-c06d-41da-9076-6af349a16789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ExpSineSquared, RationalQuadratic, RBF\n",
    "\n",
    "long_term_trend_kernel = 50.0**2 * RBF(length_scale=50.0)\n",
    "seasonal_kernel = (\n",
    "    2.0**2\n",
    "    * RBF(length_scale=100.0)\n",
    "    * ExpSineSquared(length_scale=1.0, periodicity=1.0, periodicity_bounds=\"fixed\")\n",
    ")\n",
    "# irregularities_kernel = 0.5**2 * RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "# noise_kernel = 0.1**2 * RBF(length_scale=0.1) + WhiteKernel(\n",
    "#     noise_level=0.1**2, noise_level_bounds=(1e-5, 1e5)\n",
    "# )\n",
    "kernel = (\n",
    "    long_term_trend_kernel #+ seasonal_kernel #+ irregularities_kernel + noise_kernel\n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, alpha=1e-2)\n",
    "start_time = time.time()\n",
    "gaussian_process.fit(x_train, y_train)\n",
    "print(\n",
    "    f\"Time for GaussianProcessRegressor fitting: {time.time() - start_time:.3f} seconds\"\n",
    ")\n",
    "gp_pred = gaussian_process.predict(x_test)\n",
    "print(f'R2 = {r2_score(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), gp_pred.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041a9b9-e572-489f-a6fd-2711934828cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(data_loader.y[test].flatten()[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(gp_pred.flatten()[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120fd514-c7ef-46d5-950d-591f338bd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=2000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_hat = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0f307-295d-4ed0-8e1d-5a06a1d7e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), y_hat.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3bc5f-fc96-4b28-b1b1-cf389639229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(data_loader.y[test].flatten()[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(y_hat.flatten()[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc72c6-3c63-4051-9878-218b81ea4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lambdas_hat = np.zeros((data_loader.n_trials, Nc, Nt))\n",
    "for k in range(len(train)):\n",
    "    for t in range(Nt):\n",
    "        log_lambdas_hat[k,:,t] = cavi.bs.detach().numpy() + cavi.betas[:,t].detach().numpy() * y_train[k][t]\n",
    "\n",
    "for k in range(len(test)):\n",
    "    for t in range(Nt):\n",
    "        log_lambdas_hat[k,:,t] = cavi.bs.detach().numpy() + cavi.betas[:,t].detach().numpy() * y_hat[k][t]\n",
    "\n",
    "log_pis_hat = log_lambdas_hat - logsumexp(log_lambdas_hat, 1)[:,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa90ad-7fdd-4a10-adca-a8131fd30120",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pis = np.exp(log_pis_hat)\n",
    "enc_means = cavi.means.detach().numpy()\n",
    "enc_covs = cavi.covs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b59f9a-3ddc-4e55-b1c0-0326f76c705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_all = np.zeros((data_loader.n_trials, Nc, Nt))\n",
    "\n",
    "for k in range(enc_all.shape[0]):\n",
    "    for t in range(Nt):\n",
    "        enc_gmm =  GaussianMixture(n_components=Nc, covariance_type='full')\n",
    "        enc_gmm.precisions_cholesky_ = np.linalg.cholesky(np.linalg.inv(enc_covs))\n",
    "        enc_gmm.weights_ = enc_pis[k,:,t]\n",
    "        # enc_gmm.weights_ = enc_pis[:,:,t].mean(0)\n",
    "        enc_gmm.means_ = enc_means\n",
    "        enc_gmm.covariances_ = enc_covs\n",
    "        if len(data_loader.trials[k][t]) > 0:\n",
    "            enc_all[k,:,t] = enc_gmm.predict_proba(data_loader.trials[k][t][:,1:]).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d8438-aca9-4f33-880a-5d6f6afce3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.imshow(enc_all.mean(0), aspect='auto', cmap='cubehelix')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3fcf2-eea4-4f54-b2c1-e24ed84c9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = enc_all.reshape(-1, enc_all.shape[1] * enc_all.shape[2])[train]\n",
    "x_test = enc_all.reshape(-1, enc_all.shape[1] * enc_all.shape[2])[test]\n",
    "y_train = data_loader.y[train]\n",
    "\n",
    "ridge = Ridge(alpha=2000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_hat = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6ba34-af7d-495f-8ecd-75d35325bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), y_hat.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c10cb-c84f-4909-8d05-5b0048e632bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ExpSineSquared, RationalQuadratic, RBF\n",
    "\n",
    "long_term_trend_kernel = 50.0**2 * RBF(length_scale=50.0)\n",
    "seasonal_kernel = (\n",
    "    2.0**2\n",
    "    * RBF(length_scale=100.0)\n",
    "    * ExpSineSquared(length_scale=1.0, periodicity=1.0, periodicity_bounds=\"fixed\")\n",
    ")\n",
    "# irregularities_kernel = 0.5**2 * RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "# noise_kernel = 0.1**2 * RBF(length_scale=0.1) + WhiteKernel(\n",
    "#     noise_level=0.1**2, noise_level_bounds=(1e-5, 1e5)\n",
    "# )\n",
    "kernel = (\n",
    "    long_term_trend_kernel #+ seasonal_kernel + noise_kernel #+ irregularities_kernel \n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, alpha=1e-10)\n",
    "start_time = time.time()\n",
    "gaussian_process.fit(x_train, y_train)\n",
    "print(\n",
    "    f\"Time for GaussianProcessRegressor fitting: {time.time() - start_time:.3f} seconds\"\n",
    ")\n",
    "gp_pred = gaussian_process.predict(x_test)\n",
    "print(f'R2 = {r2_score(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), gp_pred.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c8586-ab67-4aee-8437-f683d7105e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(data_loader.y[test].flatten()[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(gp_pred.flatten()[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7880ed-13c7-4955-ab9f-2f1fcb8b0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_enc_all, half_window_size, n_windows = decoder.sliding_window(\n",
    "    enc_all, \n",
    "    data_loader.n_trials,\n",
    "    window_size = 7\n",
    ")\n",
    "windowed_y = data_loader.y[:,half_window_size:n_windows].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772c029-d395-41fd-abdb-b889b325f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_by_trial = windowed_enc_all.reshape((data_loader.n_trials, -1))\n",
    "y_by_trial = windowed_y.reshape((data_loader.n_trials, -1))\n",
    "x_train, x_test = x_by_trial[train], x_by_trial[test]\n",
    "y_train, y_test = y_by_trial[train], y_by_trial[test]\n",
    "\n",
    "x_train = x_train.reshape((-1, windowed_enc_all.shape[1]))\n",
    "x_test = x_test.reshape((-1, windowed_enc_all.shape[1]))\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116659c-83a3-4d72-8c93-dcbd2ef4a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=10000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1566e79-5851-48c1-87a2-edb0104d3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(y_test, y_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(y_test, y_pred):.3f}')\n",
    "print(f'corr = {pearsonr(y_test, y_pred).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f5c3f-3436-4ce4-995b-cc552f1bcc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(y_test[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(y_pred[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536e0cf-ba8f-4efe-a565-a0a349f01ac7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c30b68-3860-4951-b448-4fa0eec07084",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_thresh, half_window_size, n_windows = decoder.sliding_window(\n",
    "    thresholded_neural_data, \n",
    "    data_loader.n_trials,\n",
    "    window_size = 7\n",
    ")\n",
    "windowed_y = data_loader.y[:,half_window_size:n_windows].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb122f-281a-4523-b70f-4c5d09939299",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_by_trial = windowed_thresh.reshape((data_loader.n_trials, -1))\n",
    "y_by_trial = windowed_y.reshape((data_loader.n_trials, -1))\n",
    "x_train, x_test = x_by_trial[train], x_by_trial[test]\n",
    "y_train, y_test = y_by_trial[train], y_by_trial[test]\n",
    "\n",
    "x_train = x_train.reshape((-1, windowed_thresh.shape[1]))\n",
    "x_test = x_test.reshape((-1, windowed_thresh.shape[1]))\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefee3d-75ce-49da-8fed-f58f7754ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=10000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f878ae-3c67-47d2-bb8c-dd593ddb79c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(y_test, y_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(y_test, y_pred):.3f}')\n",
    "print(f'corr = {pearsonr(y_test, y_pred).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663ae66-6d1d-4486-b449-c3fc6678aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(y_test[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(y_pred[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c88bb7-e74c-4279-b74f-aa3e9bd43aff",
   "metadata": {},
   "source": [
    "#### KS & good IBL units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a06582-0f91-488b-a3ab-9ef1f78412af",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = stim_on_times.shape[0]\n",
    "sorted = np.vstack([sorted_trials[i] for i in np.arange(n_trials)]) \n",
    "spike_times = sorted[:,0]\n",
    "spike_clusters = sorted[:,1]\n",
    "\n",
    "sorted_neural_data = preprocess.compute_neural_activity(\n",
    "    (spike_times, spike_clusters),\n",
    "    stim_on_times,\n",
    "    'sorted', \n",
    "    n_time_bins=30,\n",
    "    regional=True\n",
    ")\n",
    "print(f'sorted neural data shape: {sorted_neural_data.shape}')\n",
    "\n",
    "good_sorted = np.vstack([good_sorted_trials[i] for i in np.arange(n_trials)]) \n",
    "spike_times = good_sorted[:,0]\n",
    "spike_clusters = good_sorted[:,1]\n",
    "\n",
    "good_sorted_neural_data = preprocess.compute_neural_activity(\n",
    "    (spike_times, spike_clusters),\n",
    "    stim_on_times,\n",
    "    'sorted', \n",
    "    n_time_bins=30,\n",
    "    regional=True\n",
    ")\n",
    "print(f'good sorted neural data shape: {good_sorted_neural_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e018223-bf48-46c7-b868-d73d6faf0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sorted_neural_data.reshape(-1, sorted_neural_data.shape[1] * sorted_neural_data.shape[2])[train]\n",
    "x_test = sorted_neural_data.reshape(-1, sorted_neural_data.shape[1] * sorted_neural_data.shape[2])[test]\n",
    "y_train = data_loader.y[train]\n",
    "\n",
    "ridge = Ridge(alpha=2000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_hat = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053a0c9-725e-4722-addd-26c0f1fd63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), y_hat.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b049209-7c71-4c72-85fe-54b516784485",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(data_loader.y[test].flatten()[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(y_hat.flatten()[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9362aa-e387-45a6-8774-90f518abcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ExpSineSquared, RationalQuadratic, RBF\n",
    "\n",
    "long_term_trend_kernel = 50.0**2 * RBF(length_scale=50.0)\n",
    "seasonal_kernel = (\n",
    "    2.0**2\n",
    "    * RBF(length_scale=100.0)\n",
    "    * ExpSineSquared(length_scale=1.0, periodicity=1.0, periodicity_bounds=\"fixed\")\n",
    ")\n",
    "# irregularities_kernel = 0.5**2 * RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "noise_kernel = 0.1**2 * RBF(length_scale=0.1) + WhiteKernel(\n",
    "    noise_level=0.1**2, noise_level_bounds=(1e-5, 1e5)\n",
    ")\n",
    "kernel = (\n",
    "    long_term_trend_kernel #+ seasonal_kernel + noise_kernel #+ irregularities_kernel\n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, alpha=1e-2)\n",
    "start_time = time.time()\n",
    "gaussian_process.fit(x_train, y_train)\n",
    "print(\n",
    "    f\"Time for GaussianProcessRegressor fitting: {time.time() - start_time:.3f} seconds\"\n",
    ")\n",
    "gp_pred = gaussian_process.predict(x_test)\n",
    "print(f'R2 = {r2_score(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), gp_pred.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc9003-3052-431d-a66a-a58f2144be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_sorted, half_window_size, n_windows = decoder.sliding_window(\n",
    "    sorted_neural_data, \n",
    "    data_loader.n_trials,\n",
    "    window_size = 7\n",
    ")\n",
    "\n",
    "windowed_good_units, half_window_size, n_windows = decoder.sliding_window(\n",
    "    good_sorted_neural_data, \n",
    "    data_loader.n_trials,\n",
    "    window_size = 7\n",
    ")\n",
    "windowed_y = data_loader.y[:,half_window_size:n_windows].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379fe56-ed49-45ee-b5c1-09b51611b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_by_trial = windowed_sorted.reshape((data_loader.n_trials, -1))\n",
    "y_by_trial = windowed_y.reshape((data_loader.n_trials, -1))\n",
    "x_train, x_test = x_by_trial[train], x_by_trial[test]\n",
    "y_train, y_test = y_by_trial[train], y_by_trial[test]\n",
    "\n",
    "x_train = x_train.reshape((-1, windowed_sorted.shape[1]))\n",
    "x_test = x_test.reshape((-1, windowed_sorted.shape[1]))\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "ridge = Ridge(alpha=10000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d837d7e-4b9f-46a0-b0ed-2c59e967019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(y_test, y_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(y_test, y_pred):.3f}')\n",
    "print(f'corr = {pearsonr(y_test, y_pred).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a610c-c17a-48c5-9670-747cebc94453",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(y_test[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(y_pred[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9f2d4-e447-443b-aab9-8d30250e4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = good_sorted_neural_data.reshape(-1, good_sorted_neural_data.shape[1] * good_sorted_neural_data.shape[2])[train]\n",
    "x_test = good_sorted_neural_data.reshape(-1, good_sorted_neural_data.shape[1] * good_sorted_neural_data.shape[2])[test]\n",
    "y_train = data_loader.y[train]\n",
    "\n",
    "ridge = Ridge(alpha=2000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_hat = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24825a-8c8f-4597-af8d-aa650046581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], y_hat):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), y_hat.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a554ec-8f63-433b-8661-8530505017fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ExpSineSquared, RationalQuadratic, RBF\n",
    "\n",
    "long_term_trend_kernel = 50.0**2 * RBF(length_scale=50.0)\n",
    "seasonal_kernel = (\n",
    "    2.0**2\n",
    "    * RBF(length_scale=100.0)\n",
    "    * ExpSineSquared(length_scale=1.0, periodicity=1.0, periodicity_bounds=\"fixed\")\n",
    ")\n",
    "# irregularities_kernel = 0.5**2 * RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "noise_kernel = 0.1**2 * RBF(length_scale=0.1) + WhiteKernel(\n",
    "    noise_level=0.1**2, noise_level_bounds=(1e-5, 1e5)\n",
    ")\n",
    "kernel = (\n",
    "    long_term_trend_kernel #+ seasonal_kernel + noise_kernel #+ irregularities_kernel\n",
    ")\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, alpha=1e-2)\n",
    "start_time = time.time()\n",
    "gaussian_process.fit(x_train, y_train)\n",
    "print(\n",
    "    f\"Time for GaussianProcessRegressor fitting: {time.time() - start_time:.3f} seconds\"\n",
    ")\n",
    "gp_pred = gaussian_process.predict(x_test)\n",
    "print(f'R2 = {r2_score(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(data_loader.y[test], gp_pred):.3f}')\n",
    "print(f'corr = {pearsonr(data_loader.y[test].flatten(), gp_pred.flatten()).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09438e8-ed72-424f-ae30-95c0a4c26b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(data_loader.y[test].flatten()[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(gp_pred.flatten()[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ae8bd-507c-4680-af40-bc1471a6d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_by_trial = windowed_good_units.reshape((data_loader.n_trials, -1))\n",
    "y_by_trial = windowed_y.reshape((data_loader.n_trials, -1))\n",
    "x_train, x_test = x_by_trial[train], x_by_trial[test]\n",
    "y_train, y_test = y_by_trial[train], y_by_trial[test]\n",
    "\n",
    "x_train = x_train.reshape((-1, windowed_good_units.shape[1]))\n",
    "x_test = x_test.reshape((-1, windowed_good_units.shape[1]))\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "ridge = Ridge(alpha=2000)\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2025c-2f3f-4572-aa3b-837e8e4350b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 = {r2_score(y_test, y_pred):.3f}')\n",
    "print(f'MSE = {mean_squared_error(y_test, y_pred):.3f}')\n",
    "print(f'corr = {pearsonr(y_test, y_pred).statistic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30398d55-012e-4d7d-8404-b77f03f473f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.plot(y_test[:200], c='gray', linestyle='dashed', label='observed');\n",
    "plt.plot(y_pred[:200], c='blue', alpha=.6, label='predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f7a4d-cfbf-4f6a-9c96-54bd7e7682ee",
   "metadata": {},
   "source": [
    "#### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6bdc0b6-d5d9-47e1-b644-07f3b573a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "po_good_units_r2 = [0.008, 0.058, 0.066, 0.046, 0.068]\n",
    "po_all_units_r2 = [0.159, 0.164, 0.119, 0.135, 0.140]\n",
    "po_thresh_r2 = [0.138, 0.123, 0.099, 0.130, 0.145]\n",
    "po_mog_r2 = [0.102, 0.048, 0.028, 0.064, 0.049]\n",
    "po_enc_mog_r2 = [0.154, 0.170, 0.104, 0.135, 0.147]\n",
    "\n",
    "po_good_units_mse = [1.685, 1.219, 1.447, 1.423, 1.535]\n",
    "po_all_units_mse = [1.175, 0.889, 1.284, 1.193, 1.253]\n",
    "po_thresh_mse = [1.248, 1.011, 1.323, 1.209, 1.216]\n",
    "po_mog_mse = [1.329, 1.281, 1.547, 1.378, 1.597]\n",
    "po_enc_mog_mse = [1.180, 0.892, 1.308, 1.191, 1.239]\n",
    "\n",
    "po_good_units_corr = []\n",
    "po_all_units_corr = []\n",
    "po_thresh_corr = []\n",
    "po_mog_corr = []\n",
    "po_enc_mog_corr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c547f31-eeae-4e12-a457-dcbd9673c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO good units R2: 0.049 MSE: 1.462\n",
      "PO all units R2: 0.143 MSE: 1.159\n",
      "PO thresholded R2: 0.127 MSE: 1.201\n",
      "PO MoG R2: 0.058 MSE: 1.426\n",
      "PO encoded-MoG R2: 0.142 MSE: 1.162\n"
     ]
    }
   ],
   "source": [
    "print(f'PO good units R2: {np.mean(po_good_units_r2):.3f} MSE: {np.mean(po_good_units_mse):.3f}')\n",
    "print(f'PO all units R2: {np.mean(po_all_units_r2):.3f} MSE: {np.mean(po_all_units_mse):.3f}')\n",
    "print(f'PO thresholded R2: {np.mean(po_thresh_r2):.3f} MSE: {np.mean(po_thresh_mse):.3f}')\n",
    "print(f'PO MoG R2: {np.mean(po_mog_r2):.3f} MSE: {np.mean(po_mog_mse):.3f}')\n",
    "print(f'PO encoded-MoG R2: {np.mean(po_enc_mog_r2):.3f} MSE: {np.mean(po_enc_mog_mse):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f0822-d43a-4c23-8e41-f306c934c3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54aae2e-c71c-48c7-95ec-a4ea14abd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_good_units_r2 = [0.004, ]\n",
    "lp_all_units_r2 = [0.157, ]\n",
    "lp_thresh_r2 = [0.126, ]\n",
    "lp_mog_r2 = [0.053, ]\n",
    "lp_enc_mog_r2 = [0.151, ]\n",
    "\n",
    "lp_good_units_mse = [1.646, ]\n",
    "lp_all_units_mse = [1.122, ]\n",
    "lp_thresh_mse = [1.235, ]\n",
    "lp_mog_mse = [1.513, ]\n",
    "lp_enc_mog_mse = [1.136, ]\n",
    "\n",
    "lp_good_units_corr = [0.407, ]\n",
    "lp_all_units_corr = [0.667, ]\n",
    "lp_thresh_corr = [0.614, ]\n",
    "lp_mog_corr = [0.484, ]\n",
    "lp_enc_mog_corr = [0.662, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2dcab-4fd2-4516-84d3-4af9a9ca0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_good_units_mse = []\n",
    "dg_all_units_mse = []\n",
    "dg_thresh_mse = []\n",
    "dg_mog_mse = []\n",
    "dg_enc_mog_mse = []\n",
    "\n",
    "ca1_good_units_mse = []\n",
    "ca1_all_units_mse = []\n",
    "ca1_thresh_mse = []\n",
    "ca1_mog_mse = []\n",
    "ca1_enc_mog_mse = []\n",
    "\n",
    "vis_good_units_mse = []\n",
    "vis_all_units_mse = []\n",
    "vis_thresh_mse = []\n",
    "vis_mog_mse = []\n",
    "vis_enc_mog_mse = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c044e3-f285-4807-bbf1-2238a48ec67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
